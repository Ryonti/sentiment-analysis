{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Yonti's\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Yonti's\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ('G0OgL3e!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hari ini aku masih libur, masih ada waktu semi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yg ptm hari ini semangaattt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dom cilacap udh ptm 100% apa blm?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yg dom jabodetabek kalian ptm nya udah 100% kah?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yg ptm yg genap seru bgt, yg ganjil kek nya ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wtp hr ini gue libur tp BESOK PTM 100%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  hari ini aku masih libur, masih ada waktu semi...\n",
       "1                        yg ptm hari ini semangaattt\n",
       "2                  dom cilacap udh ptm 100% apa blm?\n",
       "3   yg dom jabodetabek kalian ptm nya udah 100% kah?\n",
       "4  yg ptm yg genap seru bgt, yg ganjil kek nya ba...\n",
       "5             wtp hr ini gue libur tp BESOK PTM 100%"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/small.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lower_text</th>\n",
       "      <th>remove_url</th>\n",
       "      <th>remove_num</th>\n",
       "      <th>punctuation</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hari ini aku masih libur, masih ada waktu semi...</td>\n",
       "      <td>hari ini aku masih libur, masih ada waktu semi...</td>\n",
       "      <td>hari ini aku masih libur, masih ada waktu semi...</td>\n",
       "      <td>hari ini aku masih libur, masih ada waktu semi...</td>\n",
       "      <td>hari ini aku masih libur masih ada waktu semin...</td>\n",
       "      <td>[hari, ini, aku, masih, libur, masih, ada, wak...</td>\n",
       "      <td>[libur, seminggu, rumah, manfaatin, libur, sem...</td>\n",
       "      <td>[libur, seminggu, rumah, manfaatin, libur, sem...</td>\n",
       "      <td>libur seminggu rumah manfaatin libur seminggu ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yg ptm hari ini semangaattt</td>\n",
       "      <td>yg ptm hari ini semangaattt</td>\n",
       "      <td>yg ptm hari ini semangaattt</td>\n",
       "      <td>yg ptm hari ini semangaattt</td>\n",
       "      <td>yg ptm hari ini semangaattt</td>\n",
       "      <td>[yg, ptm, hari, ini, semangaattt]</td>\n",
       "      <td>[yg, ptm, semangaattt]</td>\n",
       "      <td>[yg, ptm, semangaattt]</td>\n",
       "      <td>yg ptm semangaattt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dom cilacap udh ptm 100% apa blm?</td>\n",
       "      <td>dom cilacap udh ptm 100% apa blm?</td>\n",
       "      <td>dom cilacap udh ptm 100% apa blm?</td>\n",
       "      <td>dom cilacap udh ptm % apa blm?</td>\n",
       "      <td>dom cilacap udh ptm  apa blm</td>\n",
       "      <td>[dom, cilacap, udh, ptm, apa, blm]</td>\n",
       "      <td>[dom, cilacap, udh, ptm, blm]</td>\n",
       "      <td>[dom, cilacap, udh, ptm, blm]</td>\n",
       "      <td>dom cilacap udh ptm blm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yg dom jabodetabek kalian ptm nya udah 100% kah?</td>\n",
       "      <td>yg dom jabodetabek kalian ptm nya udah 100% kah?</td>\n",
       "      <td>yg dom jabodetabek kalian ptm nya udah 100% kah?</td>\n",
       "      <td>yg dom jabodetabek kalian ptm nya udah % kah?</td>\n",
       "      <td>yg dom jabodetabek kalian ptm nya udah  kah</td>\n",
       "      <td>[yg, dom, jabodetabek, kalian, ptm, nya, udah,...</td>\n",
       "      <td>[yg, dom, jabodetabek, ptm, nya, udah, kah]</td>\n",
       "      <td>[yg, dom, jabodetabek, ptm, nya, udah, kah]</td>\n",
       "      <td>yg dom jabodetabek ptm nya udah kah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yg ptm yg genap seru bgt, yg ganjil kek nya ba...</td>\n",
       "      <td>yg ptm yg genap seru bgt, yg ganjil kek nya ba...</td>\n",
       "      <td>yg ptm yg genap seru bgt, yg ganjil kek nya ba...</td>\n",
       "      <td>yg ptm yg genap seru bgt, yg ganjil kek nya ba...</td>\n",
       "      <td>yg ptm yg genap seru bgt yg ganjil kek nya bak...</td>\n",
       "      <td>[yg, ptm, yg, genap, seru, bgt, yg, ganjil, ke...</td>\n",
       "      <td>[yg, ptm, yg, genap, seru, bgt, yg, ganjil, ke...</td>\n",
       "      <td>[yg, ptm, yg, genap, seru, bgt, yg, ganjil, ke...</td>\n",
       "      <td>yg ptm yg genap seru bgt yg ganjil kek nya sep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  hari ini aku masih libur, masih ada waktu semi...   \n",
       "1                        yg ptm hari ini semangaattt   \n",
       "2                  dom cilacap udh ptm 100% apa blm?   \n",
       "3   yg dom jabodetabek kalian ptm nya udah 100% kah?   \n",
       "4  yg ptm yg genap seru bgt, yg ganjil kek nya ba...   \n",
       "\n",
       "                                          lower_text  \\\n",
       "0  hari ini aku masih libur, masih ada waktu semi...   \n",
       "1                        yg ptm hari ini semangaattt   \n",
       "2                  dom cilacap udh ptm 100% apa blm?   \n",
       "3   yg dom jabodetabek kalian ptm nya udah 100% kah?   \n",
       "4  yg ptm yg genap seru bgt, yg ganjil kek nya ba...   \n",
       "\n",
       "                                          remove_url  \\\n",
       "0  hari ini aku masih libur, masih ada waktu semi...   \n",
       "1                        yg ptm hari ini semangaattt   \n",
       "2                  dom cilacap udh ptm 100% apa blm?   \n",
       "3   yg dom jabodetabek kalian ptm nya udah 100% kah?   \n",
       "4  yg ptm yg genap seru bgt, yg ganjil kek nya ba...   \n",
       "\n",
       "                                          remove_num  \\\n",
       "0  hari ini aku masih libur, masih ada waktu semi...   \n",
       "1                        yg ptm hari ini semangaattt   \n",
       "2                     dom cilacap udh ptm % apa blm?   \n",
       "3      yg dom jabodetabek kalian ptm nya udah % kah?   \n",
       "4  yg ptm yg genap seru bgt, yg ganjil kek nya ba...   \n",
       "\n",
       "                                         punctuation  \\\n",
       "0  hari ini aku masih libur masih ada waktu semin...   \n",
       "1                        yg ptm hari ini semangaattt   \n",
       "2                       dom cilacap udh ptm  apa blm   \n",
       "3        yg dom jabodetabek kalian ptm nya udah  kah   \n",
       "4  yg ptm yg genap seru bgt yg ganjil kek nya bak...   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  [hari, ini, aku, masih, libur, masih, ada, wak...   \n",
       "1                  [yg, ptm, hari, ini, semangaattt]   \n",
       "2                 [dom, cilacap, udh, ptm, apa, blm]   \n",
       "3  [yg, dom, jabodetabek, kalian, ptm, nya, udah,...   \n",
       "4  [yg, ptm, yg, genap, seru, bgt, yg, ganjil, ke...   \n",
       "\n",
       "                                           stopwords  \\\n",
       "0  [libur, seminggu, rumah, manfaatin, libur, sem...   \n",
       "1                             [yg, ptm, semangaattt]   \n",
       "2                      [dom, cilacap, udh, ptm, blm]   \n",
       "3        [yg, dom, jabodetabek, ptm, nya, udah, kah]   \n",
       "4  [yg, ptm, yg, genap, seru, bgt, yg, ganjil, ke...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  [libur, seminggu, rumah, manfaatin, libur, sem...   \n",
       "1                             [yg, ptm, semangaattt]   \n",
       "2                      [dom, cilacap, udh, ptm, blm]   \n",
       "3        [yg, dom, jabodetabek, ptm, nya, udah, kah]   \n",
       "4  [yg, ptm, yg, genap, seru, bgt, yg, ganjil, ke...   \n",
       "\n",
       "                                          normalized  \n",
       "0  libur seminggu rumah manfaatin libur seminggu ...  \n",
       "1                                 yg ptm semangaattt  \n",
       "2                            dom cilacap udh ptm blm  \n",
       "3                yg dom jabodetabek ptm nya udah kah  \n",
       "4  yg ptm yg genap seru bgt yg ganjil kek nya sep...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lower_text']=df['text'].str.lower()  # Convert to lowercase\n",
    "df['remove_url']=df['lower_text'].apply(lambda x: re.sub(r\"http\\S+\", \"\", x))    # remove url\n",
    "df['remove_num']=df['remove_url'].apply(lambda x: re.sub(r'\\d+', '', x))    # Remove number\n",
    "df['punctuation']=df['remove_num'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))    # Remove punctuation\n",
    "df['tokenized_text']=df['punctuation'].apply(nltk.word_tokenize) # Tokenize the text\n",
    "\n",
    "# Get the Indonesian stopwords\n",
    "indonesian_stopwords = set(nltk.corpus.stopwords.words('indonesian'))\n",
    "\n",
    "# Remove the stopwords from the tokenized texts\n",
    "df['stopwords']=df['tokenized_text'].apply(lambda x: [w for w in x if not w in indonesian_stopwords])\n",
    "\n",
    "# Initialize the Porter stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Stem the tokenized texts in the 'stopwords' column of the dataframe\n",
    "df['stemmed']=df['stopwords'].apply(lambda x: [stemmer.stem(w) for w in x])\n",
    "\n",
    "df['normalized']=df['stemmed'].apply(lambda x: ' '.join(x)) # Join the stemmed words into a single string\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_text = text.lower()   # Convert text to lower\n",
    "\n",
    "token_text = re.sub(r\"\\d+\", \"\", lower_text)    # Remove number\n",
    "token_text = re.sub('\\s+',' ', token_text) # Remove multiple whitespace into single whitespace\n",
    "token_text = ''.join(c for c in token_text if c not in string.punctuation)      # Remove punctuation\n",
    "word_tokens = nltk.tokenize.word_tokenize(token_text)    # Tokenize the text\n",
    "freq_tokens = nltk.FreqDist(word_tokens)    # Frequency word token\n",
    "\n",
    "stop_words = [w for w in x if not w in indonesian_stopwords]   # Implement stopwords\n",
    "\n",
    "stemmed_words = [stemmer.stem(w) for w in x]   # Stem the words\n",
    "\n",
    "normalized_text = ''.join(stemmed_words)  # Join the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case Folding Result : g0ogl3e!\n",
      "Remove punctuation, number, multiple whitespace : gogle\n",
      "Tokenizing Result :  ['gogle']\n",
      "Frequency Token :  [('gogle', 1)]\n",
      "Stopword :  ['gogle']\n",
      "Stemmer :  ['gogl']\n",
      "Normalized :  gogl\n"
     ]
    }
   ],
   "source": [
    "print(f'Case Folding Result : {lower_text}')\n",
    "print(f'Remove punctuation, number, multiple whitespace : {token_text}')\n",
    "print('Tokenizing Result : ',word_tokens)\n",
    "print('Frequency Token : ',freq_tokens.most_common())\n",
    "print('Stopword : ',stop_words)\n",
    "print('Stemmer : ',stemmed_words)\n",
    "print('Normalized : ',normalized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Sentiment Analysis and labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n",
      "1    1.0\n",
      "2    1.0\n",
      "3    1.0\n",
      "4    1.0\n",
      "5    1.0\n",
      "Name: sentiment, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df['textblob'] = df['normalized'].apply(lambda x: TextBlob(x))\n",
    "\n",
    "# Create a new column in the DataFrame with sentiment analysis scores\n",
    "df['sentiment'] = df['textblob'].apply(lambda x: x.sentiment.polarity)\n",
    "\n",
    "# Normalize the sentiment scores to range from -1 (negative) to 1 (positive)\n",
    "df['sentiment'] = df['sentiment'].apply(lambda x: np.interp(x, [df['sentiment'].min(), df['sentiment'].max()], [-1, 1]))\n",
    "\n",
    "print(df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral sentiment\n"
     ]
    }
   ],
   "source": [
    "analysis = TextBlob(normalized_text)\n",
    "\n",
    "# Get sentiment polarity (-1 to 1: negative to positive)\n",
    "sentiment = analysis.sentiment.polarity\n",
    "if sentiment > 0: \n",
    "    print(\"Positive sentiment\")\n",
    "elif sentiment < 0: \n",
    "    print(\"Negative sentiment\")\n",
    "else: \n",
    "    print(\"Neutral sentiment\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Yonti's\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Yonti's\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   text       300 non-null    object\n",
      " 1   sentiment  300 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 4.8+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/twitter.csv')\n",
    "\n",
    "df.head()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "0    100\n",
       "1    100\n",
       "2    100\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>twitter sepi anjir. ini pada ptm semua kali ya</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kok orang-orang seneng PTM 100%</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>skolahku 100% ptm gk ya</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kalian hariini ada yang uda ptm 100%? ada wakt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ngerant selama ptm keliatannya asik deh gue ga...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0     twitter sepi anjir. ini pada ptm semua kali ya          0\n",
       "1                    kok orang-orang seneng PTM 100%          0\n",
       "2                            skolahku 100% ptm gk ya          0\n",
       "3  kalian hariini ada yang uda ptm 100%? ada wakt...          0\n",
       "4  ngerant selama ptm keliatannya asik deh gue ga...          0"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Shuffle the dataframe\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Create a new dataframe with a random sample of 100 rows from each class\n",
    "data = pd.concat([df[df['sentiment']==0].sample(n=100), \n",
    "                  df[df['sentiment']==1].sample(n=100), \n",
    "                  df[df['sentiment']==2].sample(n=100)])\n",
    "\n",
    "# Reset the index of the new dataframe\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "# Display the value counts of the sentiment column in the new dataframe\n",
    "display(data['sentiment'].value_counts())\n",
    "data.head() # Show dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lower_text']=data['text'].str.lower()  # Convert to lowercase\n",
    "data['remove_url']=data['lower_text'].apply(lambda x: re.sub(r\"http\\S+\", \"\", x))    # remove url\n",
    "data['remove_num']=data['remove_url'].apply(lambda x: re.sub(r'\\d+', '', x))    # Remove number\n",
    "data['punctuation']=data['remove_num'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))    # Remove punctuation\n",
    "data['tokenized_text']=data['punctuation'].apply(nltk.word_tokenize) # Tokenize the text\n",
    "\n",
    "# Get the Indonesian stopwords\n",
    "indonesian_stopwords = set(nltk.corpus.stopwords.words('indonesian'))\n",
    "\n",
    "# Remove the stopwords from the tokenized texts\n",
    "data['stopwords']=data['tokenized_text'].apply(lambda x: [w for w in x if not w in indonesian_stopwords])\n",
    "\n",
    "# Initialize the Porter stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Stem the tokenized texts in the 'stopwords' column of the dataframe\n",
    "data['stemmed']=data['stopwords'].apply(lambda x: [stemmer.stem(w) for w in x])\n",
    "\n",
    "data['normalized']=data['stemmed'].apply(lambda x: ' '.join(x)) # Join the stemmed words into a single string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>lower_text</th>\n",
       "      <th>remove_url</th>\n",
       "      <th>remove_num</th>\n",
       "      <th>punctuation</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>twitter sepi anjir. ini pada ptm semua kali ya</td>\n",
       "      <td>0</td>\n",
       "      <td>twitter sepi anjir. ini pada ptm semua kali ya</td>\n",
       "      <td>twitter sepi anjir. ini pada ptm semua kali ya</td>\n",
       "      <td>twitter sepi anjir. ini pada ptm semua kali ya</td>\n",
       "      <td>twitter sepi anjir ini pada ptm semua kali ya</td>\n",
       "      <td>[twitter, sepi, anjir, ini, pada, ptm, semua, ...</td>\n",
       "      <td>[twitter, sepi, anjir, ptm, kali, ya]</td>\n",
       "      <td>[twitter, sepi, anjir, ptm, kali, ya]</td>\n",
       "      <td>twitter sepi anjir ptm kali ya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kok orang-orang seneng PTM 100%</td>\n",
       "      <td>0</td>\n",
       "      <td>kok orang-orang seneng ptm 100%</td>\n",
       "      <td>kok orang-orang seneng ptm 100%</td>\n",
       "      <td>kok orang-orang seneng ptm %</td>\n",
       "      <td>kok orangorang seneng ptm</td>\n",
       "      <td>[kok, orangorang, seneng, ptm]</td>\n",
       "      <td>[orangorang, seneng, ptm]</td>\n",
       "      <td>[orangorang, seneng, ptm]</td>\n",
       "      <td>orangorang seneng ptm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>skolahku 100% ptm gk ya</td>\n",
       "      <td>0</td>\n",
       "      <td>skolahku 100% ptm gk ya</td>\n",
       "      <td>skolahku 100% ptm gk ya</td>\n",
       "      <td>skolahku % ptm gk ya</td>\n",
       "      <td>skolahku  ptm gk ya</td>\n",
       "      <td>[skolahku, ptm, gk, ya]</td>\n",
       "      <td>[skolahku, ptm, gk, ya]</td>\n",
       "      <td>[skolahku, ptm, gk, ya]</td>\n",
       "      <td>skolahku ptm gk ya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kalian hariini ada yang uda ptm 100%? ada wakt...</td>\n",
       "      <td>0</td>\n",
       "      <td>kalian hariini ada yang uda ptm 100%? ada wakt...</td>\n",
       "      <td>kalian hariini ada yang uda ptm 100%? ada wakt...</td>\n",
       "      <td>kalian hariini ada yang uda ptm %? ada waktu i...</td>\n",
       "      <td>kalian hariini ada yang uda ptm  ada waktu ist...</td>\n",
       "      <td>[kalian, hariini, ada, yang, uda, ptm, ada, wa...</td>\n",
       "      <td>[hariini, uda, ptm, istirahat, gaa, ptm, sampe...</td>\n",
       "      <td>[hariini, uda, ptm, istirahat, gaa, ptm, samp,...</td>\n",
       "      <td>hariini uda ptm istirahat gaa ptm samp jam ber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ngerant selama ptm keliatannya asik deh gue ga...</td>\n",
       "      <td>0</td>\n",
       "      <td>ngerant selama ptm keliatannya asik deh gue ga...</td>\n",
       "      <td>ngerant selama ptm keliatannya asik deh gue ga...</td>\n",
       "      <td>ngerant selama ptm keliatannya asik deh gue ga...</td>\n",
       "      <td>ngerant selama ptm keliatannya asik deh gue ga...</td>\n",
       "      <td>[ngerant, selama, ptm, keliatannya, asik, deh,...</td>\n",
       "      <td>[ngerant, ptm, keliatannya, asik, deh, gue, ga...</td>\n",
       "      <td>[ngerant, ptm, keliatannya, asik, deh, gue, ga...</td>\n",
       "      <td>ngerant ptm keliatannya asik deh gue gabisaa n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment  \\\n",
       "0     twitter sepi anjir. ini pada ptm semua kali ya          0   \n",
       "1                    kok orang-orang seneng PTM 100%          0   \n",
       "2                            skolahku 100% ptm gk ya          0   \n",
       "3  kalian hariini ada yang uda ptm 100%? ada wakt...          0   \n",
       "4  ngerant selama ptm keliatannya asik deh gue ga...          0   \n",
       "\n",
       "                                          lower_text  \\\n",
       "0     twitter sepi anjir. ini pada ptm semua kali ya   \n",
       "1                    kok orang-orang seneng ptm 100%   \n",
       "2                            skolahku 100% ptm gk ya   \n",
       "3  kalian hariini ada yang uda ptm 100%? ada wakt...   \n",
       "4  ngerant selama ptm keliatannya asik deh gue ga...   \n",
       "\n",
       "                                          remove_url  \\\n",
       "0     twitter sepi anjir. ini pada ptm semua kali ya   \n",
       "1                    kok orang-orang seneng ptm 100%   \n",
       "2                            skolahku 100% ptm gk ya   \n",
       "3  kalian hariini ada yang uda ptm 100%? ada wakt...   \n",
       "4  ngerant selama ptm keliatannya asik deh gue ga...   \n",
       "\n",
       "                                          remove_num  \\\n",
       "0     twitter sepi anjir. ini pada ptm semua kali ya   \n",
       "1                       kok orang-orang seneng ptm %   \n",
       "2                               skolahku % ptm gk ya   \n",
       "3  kalian hariini ada yang uda ptm %? ada waktu i...   \n",
       "4  ngerant selama ptm keliatannya asik deh gue ga...   \n",
       "\n",
       "                                         punctuation  \\\n",
       "0      twitter sepi anjir ini pada ptm semua kali ya   \n",
       "1                         kok orangorang seneng ptm    \n",
       "2                                skolahku  ptm gk ya   \n",
       "3  kalian hariini ada yang uda ptm  ada waktu ist...   \n",
       "4  ngerant selama ptm keliatannya asik deh gue ga...   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  [twitter, sepi, anjir, ini, pada, ptm, semua, ...   \n",
       "1                     [kok, orangorang, seneng, ptm]   \n",
       "2                            [skolahku, ptm, gk, ya]   \n",
       "3  [kalian, hariini, ada, yang, uda, ptm, ada, wa...   \n",
       "4  [ngerant, selama, ptm, keliatannya, asik, deh,...   \n",
       "\n",
       "                                           stopwords  \\\n",
       "0              [twitter, sepi, anjir, ptm, kali, ya]   \n",
       "1                          [orangorang, seneng, ptm]   \n",
       "2                            [skolahku, ptm, gk, ya]   \n",
       "3  [hariini, uda, ptm, istirahat, gaa, ptm, sampe...   \n",
       "4  [ngerant, ptm, keliatannya, asik, deh, gue, ga...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0              [twitter, sepi, anjir, ptm, kali, ya]   \n",
       "1                          [orangorang, seneng, ptm]   \n",
       "2                            [skolahku, ptm, gk, ya]   \n",
       "3  [hariini, uda, ptm, istirahat, gaa, ptm, samp,...   \n",
       "4  [ngerant, ptm, keliatannya, asik, deh, gue, ga...   \n",
       "\n",
       "                                          normalized  \n",
       "0                     twitter sepi anjir ptm kali ya  \n",
       "1                              orangorang seneng ptm  \n",
       "2                                 skolahku ptm gk ya  \n",
       "3  hariini uda ptm istirahat gaa ptm samp jam ber...  \n",
       "4  ngerant ptm keliatannya asik deh gue gabisaa n...  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      {'twitter': 1, 'sepi': 1, 'anjir': 1, 'ini': 1...\n",
       "1      {'kok': 1, 'orangorang': 1, 'seneng': 1, 'ptm'...\n",
       "2            {'skolahku': 1, 'ptm': 1, 'gk': 1, 'ya': 1}\n",
       "3      {'kalian': 1, 'hariini': 1, 'ada': 2, 'yang': ...\n",
       "4      {'ngerant': 2, 'selama': 1, 'ptm': 1, 'keliata...\n",
       "                             ...                        \n",
       "295      {'gabung': 1, 'banget': 1, 'ptm': 1, 'gini': 1}\n",
       "296    {'ptm': 1, 'mental': 1, 'gw': 1, 'gk': 1, 'sia...\n",
       "297    {'abis': 1, 'ngomongin': 1, 'ptm': 2, 'sama': ...\n",
       "298                       {'ptm': 1, 'ga': 1, 'asik': 1}\n",
       "299    {'mampus': 1, 'ptm': 1, 'hari': 1, 'siang': 2,...\n",
       "Name: freq_token, Length: 300, dtype: object"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['freq_token']=data['tokenized_text'].apply(nltk.FreqDist).apply(lambda x: dict(x)) # Frequency word token\n",
    "\n",
    "data['freq_token']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (240,) (240,) Test:  ((60,), (60,))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data random 80%\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Train: \",X_train.shape,y_train.shape,\"Test: \",(X_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names:  ['aaa' 'aaaa' 'aaakkk' 'aamiin' 'abi' 'abieezzz' 'absen' 'adakan'\n",
      " 'adaptasi' 'adek']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create Tfidf vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Convert the 'review' column into its TF-IDF vectorized form\n",
    "X = vectorizer.fit_transform(data['normalized'])\n",
    "\n",
    "# Get the feature names (word tokens)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(\"Feature Names: \",feature_names[:10]) # Print only first 5 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train and Evaluate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score    support\n",
      "0              0.428571  0.600000  0.500000  20.000000\n",
      "1              0.722222  0.650000  0.684211  20.000000\n",
      "2              0.642857  0.450000  0.529412  20.000000\n",
      "accuracy       0.566667  0.566667  0.566667   0.566667\n",
      "macro avg      0.597884  0.566667  0.571207  60.000000\n",
      "weighted avg   0.597884  0.566667  0.571207  60.000000\n",
      "\n",
      "Accuracy of the model: 56.67%\n"
     ]
    }
   ],
   "source": [
    "# Convert training and test datasets into vectorized form\n",
    "X_train_vectorized =  vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Create a Multinomial Naive Bayes model\n",
    "model = MultinomialNB(alpha=1)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Predict sentiment for test dataset\n",
    "y_pred = model.predict(X_test_vectorized)\n",
    "\n",
    "report=classification_report(y_test, y_pred,output_dict=True)\n",
    "print(pd.DataFrame(report).transpose())\n",
    "\n",
    "# Calculate accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred, normalize=True)\n",
    "print(f'\\nAccuracy of the model: {accuracy*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

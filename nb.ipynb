{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Yonti's\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hari ini aku masih libur, masih ada waktu semi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yg ptm hari ini semangaattt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yg lagi ptm sini ciss dulu</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yang ptm semangat ya</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yang ptm selamat menikmati hari bahagia kalian ya</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  hari ini aku masih libur, masih ada waktu semi...          1\n",
       "1                        yg ptm hari ini semangaattt          1\n",
       "2                         yg lagi ptm sini ciss dulu          1\n",
       "3                               yang ptm semangat ya          1\n",
       "4  yang ptm selamat menikmati hari bahagia kalian ya          1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/twitter.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                                                   text  sentiment  \\\n",
      "0    hari ini aku masih libur, masih ada waktu semi...          1   \n",
      "1                          yg ptm hari ini semangaattt          1   \n",
      "2                           yg lagi ptm sini ciss dulu          1   \n",
      "3                                 yang ptm semangat ya          1   \n",
      "4    yang ptm selamat menikmati hari bahagia kalian ya          1   \n",
      "..                                                 ...        ...   \n",
      "295  IHHH YANG PTM JAMKOS MULU, giliran sesi gue ga...          2   \n",
      "296  Hari pertama ptm udah ada tugas kelompok aja, ...          2   \n",
      "297  Hari pertama ptm full ditambah lagi dapet itu ...          2   \n",
      "298                    Hari pertama PTM, ngantuk berat          2   \n",
      "299  Hadahh baru hari pertama ptm udah dengerin ora...          2   \n",
      "\n",
      "                                            lower_text  \\\n",
      "0    hari ini aku masih libur, masih ada waktu semi...   \n",
      "1                          yg ptm hari ini semangaattt   \n",
      "2                           yg lagi ptm sini ciss dulu   \n",
      "3                                 yang ptm semangat ya   \n",
      "4    yang ptm selamat menikmati hari bahagia kalian ya   \n",
      "..                                                 ...   \n",
      "295  ihhh yang ptm jamkos mulu, giliran sesi gue ga...   \n",
      "296  hari pertama ptm udah ada tugas kelompok aja, ...   \n",
      "297  hari pertama ptm full ditambah lagi dapet itu ...   \n",
      "298                    hari pertama ptm, ngantuk berat   \n",
      "299  hadahh baru hari pertama ptm udah dengerin ora...   \n",
      "\n",
      "                                         remove_number  \\\n",
      "0    hari ini aku masih libur, masih ada waktu semi...   \n",
      "1                          yg ptm hari ini semangaattt   \n",
      "2                           yg lagi ptm sini ciss dulu   \n",
      "3                                 yang ptm semangat ya   \n",
      "4    yang ptm selamat menikmati hari bahagia kalian ya   \n",
      "..                                                 ...   \n",
      "295  ihhh yang ptm jamkos mulu, giliran sesi gue ga...   \n",
      "296  hari pertama ptm udah ada tugas kelompok aja, ...   \n",
      "297  hari pertama ptm full ditambah lagi dapet itu ...   \n",
      "298                    hari pertama ptm, ngantuk berat   \n",
      "299  hadahh baru hari pertama ptm udah dengerin ora...   \n",
      "\n",
      "                                           punctuation  \\\n",
      "0    hari ini aku masih libur, masih ada waktu semi...   \n",
      "1                          yg ptm hari ini semangaattt   \n",
      "2                           yg lagi ptm sini ciss dulu   \n",
      "3                                 yang ptm semangat ya   \n",
      "4    yang ptm selamat menikmati hari bahagia kalian ya   \n",
      "..                                                 ...   \n",
      "295  ihhh yang ptm jamkos mulu, giliran sesi gue ga...   \n",
      "296  hari pertama ptm udah ada tugas kelompok aja, ...   \n",
      "297  hari pertama ptm full ditambah lagi dapet itu ...   \n",
      "298                    hari pertama ptm, ngantuk berat   \n",
      "299  hadahh baru hari pertama ptm udah dengerin ora...   \n",
      "\n",
      "                                        tokenized_text  \\\n",
      "0    [hari, ini, aku, masih, libur, ,, masih, ada, ...   \n",
      "1                    [yg, ptm, hari, ini, semangaattt]   \n",
      "2                    [yg, lagi, ptm, sini, ciss, dulu]   \n",
      "3                            [yang, ptm, semangat, ya]   \n",
      "4    [yang, ptm, selamat, menikmati, hari, bahagia,...   \n",
      "..                                                 ...   \n",
      "295  [ihhh, yang, ptm, jamkos, mulu, ,, giliran, se...   \n",
      "296  [hari, pertama, ptm, udah, ada, tugas, kelompo...   \n",
      "297  [hari, pertama, ptm, full, ditambah, lagi, dap...   \n",
      "298            [hari, pertama, ptm, ,, ngantuk, berat]   \n",
      "299  [hadahh, baru, hari, pertama, ptm, udah, denge...   \n",
      "\n",
      "                                            freq_token  \\\n",
      "0    {'hari': 2, 'ini': 3, 'aku': 2, 'masih': 2, 'l...   \n",
      "1    {'yg': 1, 'ptm': 1, 'hari': 1, 'ini': 1, 'sema...   \n",
      "2    {'yg': 1, 'lagi': 1, 'ptm': 1, 'sini': 1, 'cis...   \n",
      "3        {'yang': 1, 'ptm': 1, 'semangat': 1, 'ya': 1}   \n",
      "4    {'yang': 1, 'ptm': 1, 'selamat': 1, 'menikmati...   \n",
      "..                                                 ...   \n",
      "295  {'ihhh': 1, 'yang': 1, 'ptm': 1, 'jamkos': 3, ...   \n",
      "296  {'hari': 1, 'pertama': 1, 'ptm': 1, 'udah': 1,...   \n",
      "297  {'hari': 1, 'pertama': 1, 'ptm': 1, 'full': 1,...   \n",
      "298  {'hari': 1, 'pertama': 1, 'ptm': 1, ',': 1, 'n...   \n",
      "299  {'hadahh': 1, 'baru': 1, 'hari': 1, 'pertama':...   \n",
      "\n",
      "                                               stemmed  \n",
      "0    hari ini aku masih libur, masih ada waktu semi...  \n",
      "1                          yg ptm hari ini semangaattt  \n",
      "2                           yg lagi ptm sini ciss dulu  \n",
      "3                                 yang ptm semangat ya  \n",
      "4    yang ptm selamat menikmati hari bahagia kalian ya  \n",
      "..                                                 ...  \n",
      "295  ihhh yang ptm jamkos mulu, giliran sesi gue ga...  \n",
      "296  hari pertama ptm udah ada tugas kelompok aja, ...  \n",
      "297  hari pertama ptm full ditambah lagi dapet itu ...  \n",
      "298                    hari pertama ptm, ngantuk berat  \n",
      "299  hadahh baru hari pertama ptm udah dengerin ora...  \n",
      "\n",
      "[300 rows x 8 columns]>\n"
     ]
    }
   ],
   "source": [
    "df['lower_text'] = df['text'].str.lower()  # Convert to lowercase\n",
    "df['remove_number'] = df['lower_text'].str.replace(r'\\d+', '') # Remove number\n",
    "df['punctuation'] = df['remove_number'].str.replace('[^\\w\\s]', '')  # Remove punctuation\n",
    "df['tokenized_text'] = df['punctuation'].apply(nltk.word_tokenize) # Tokenize the text\n",
    "df['freq_token'] = df['tokenized_text'].apply(nltk.FreqDist).apply(lambda x: dict(x)) # Frequency word token\n",
    "df['stemmed'] = df['punctuation'].apply(lambda x: ' '.join(nltk.corpus.stopwords.words('indonesia') if x.lower() in nltk.corpus.stopwords.words('english') else [x]))\n",
    "\n",
    "print(df.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tfidf vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Convert the 'review' column into its TF-IDF vectorized form\n",
    "X = vectorizer.fit_transform(df['punctuation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train and Evaluate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data random 80%\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert training and test datasets into vectorized form\n",
    "X_train_vectorized =  vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Create a Multinomial Naive Bayes model\n",
    "model = MultinomialNB(alpha=1)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Predict sentiment for test dataset\n",
    "y_pred = model.predict(X_test_vectorized)\n",
    "\n",
    "# Calculate accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred, normalize=True)\n",
    "print(f'Accuracy of the model: {accuracy*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

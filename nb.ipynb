{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Yonti's\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Yonti's\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   text       300 non-null    object\n",
      " 1   sentiment  300 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 4.8+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/twitter.csv')\n",
    "\n",
    "df.head()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "0    100\n",
       "1    100\n",
       "2    100\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gua harusnya hari ini ptm</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>belom ada ptm ygy https://t.co/lMYicodnts</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>twt sepi bgt pada ptm yaa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oi kalian ptm nya gimana?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sp yg hr ini ptm cungg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        text  sentiment\n",
       "0                  gua harusnya hari ini ptm          0\n",
       "1  belom ada ptm ygy https://t.co/lMYicodnts          0\n",
       "2                  twt sepi bgt pada ptm yaa          0\n",
       "3                  oi kalian ptm nya gimana?          0\n",
       "4                     sp yg hr ini ptm cungg          0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Shuffle the dataframe\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Create a new dataframe with a random sample of 100 rows from each class\n",
    "data = pd.concat([df[df['sentiment']==0].sample(n=100), \n",
    "                  df[df['sentiment']==1].sample(n=100), \n",
    "                  df[df['sentiment']==2].sample(n=100)])\n",
    "\n",
    "# Reset the index of the new dataframe\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "# Display the value counts of the sentiment column in the new dataframe\n",
    "display(data['sentiment'].value_counts())\n",
    "data.head() # Show dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lower_text'] = data['text'].str.lower()  # Convert to lowercase\n",
    "data['remove_url']=data['lower_text'].apply(lambda x: re.sub(r\"http\\S+\", \"\", x))    # remove url\n",
    "data['remove_num']=data['remove_url'].apply(lambda x: re.sub(r'\\d+', '', x))    # Remove number\n",
    "data['punctuation']=data['remove_num'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))    # Remove punctuation\n",
    "data['tokenized_text']=data['punctuation'].apply(nltk.word_tokenize) # Tokenize the text\n",
    "\n",
    "# Get the Indonesian stopwords\n",
    "indonesian_stopwords = set(nltk.corpus.stopwords.words('indonesian'))\n",
    "\n",
    "# Remove the stopwords from the tokenized texts\n",
    "data['stopwords']=data['tokenized_text'].apply(lambda x: [w for w in x if not w in indonesian_stopwords])\n",
    "\n",
    "# Initialize the Porter stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Stem the tokenized texts in the 'stopwords' column of the dataframe\n",
    "data['stemmed']=data['stopwords'].apply(lambda x: [stemmer.stem(w) for w in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>lower_text</th>\n",
       "      <th>remove_url</th>\n",
       "      <th>remove_num</th>\n",
       "      <th>punctuation</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gua harusnya hari ini ptm</td>\n",
       "      <td>0</td>\n",
       "      <td>gua harusnya hari ini ptm</td>\n",
       "      <td>gua harusnya hari ini ptm</td>\n",
       "      <td>gua harusnya hari ini ptm</td>\n",
       "      <td>gua harusnya hari ini ptm</td>\n",
       "      <td>[gua, harusnya, hari, ini, ptm]</td>\n",
       "      <td>[gua, ptm]</td>\n",
       "      <td>[gua, ptm]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>belom ada ptm ygy https://t.co/lMYicodnts</td>\n",
       "      <td>0</td>\n",
       "      <td>belom ada ptm ygy https://t.co/lmyicodnts</td>\n",
       "      <td>belom ada ptm ygy</td>\n",
       "      <td>belom ada ptm ygy</td>\n",
       "      <td>belom ada ptm ygy</td>\n",
       "      <td>[belom, ada, ptm, ygy]</td>\n",
       "      <td>[belom, ptm, ygy]</td>\n",
       "      <td>[belom, ptm, ygi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>twt sepi bgt pada ptm yaa</td>\n",
       "      <td>0</td>\n",
       "      <td>twt sepi bgt pada ptm yaa</td>\n",
       "      <td>twt sepi bgt pada ptm yaa</td>\n",
       "      <td>twt sepi bgt pada ptm yaa</td>\n",
       "      <td>twt sepi bgt pada ptm yaa</td>\n",
       "      <td>[twt, sepi, bgt, pada, ptm, yaa]</td>\n",
       "      <td>[twt, sepi, bgt, ptm, yaa]</td>\n",
       "      <td>[twt, sepi, bgt, ptm, yaa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oi kalian ptm nya gimana?</td>\n",
       "      <td>0</td>\n",
       "      <td>oi kalian ptm nya gimana?</td>\n",
       "      <td>oi kalian ptm nya gimana?</td>\n",
       "      <td>oi kalian ptm nya gimana?</td>\n",
       "      <td>oi kalian ptm nya gimana</td>\n",
       "      <td>[oi, kalian, ptm, nya, gimana]</td>\n",
       "      <td>[oi, ptm, nya, gimana]</td>\n",
       "      <td>[oi, ptm, nya, gimana]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sp yg hr ini ptm cungg</td>\n",
       "      <td>0</td>\n",
       "      <td>sp yg hr ini ptm cungg</td>\n",
       "      <td>sp yg hr ini ptm cungg</td>\n",
       "      <td>sp yg hr ini ptm cungg</td>\n",
       "      <td>sp yg hr ini ptm cungg</td>\n",
       "      <td>[sp, yg, hr, ini, ptm, cungg]</td>\n",
       "      <td>[sp, yg, hr, ptm, cungg]</td>\n",
       "      <td>[sp, yg, hr, ptm, cungg]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        text  sentiment  \\\n",
       "0                  gua harusnya hari ini ptm          0   \n",
       "1  belom ada ptm ygy https://t.co/lMYicodnts          0   \n",
       "2                  twt sepi bgt pada ptm yaa          0   \n",
       "3                  oi kalian ptm nya gimana?          0   \n",
       "4                     sp yg hr ini ptm cungg          0   \n",
       "\n",
       "                                  lower_text                 remove_url  \\\n",
       "0                  gua harusnya hari ini ptm  gua harusnya hari ini ptm   \n",
       "1  belom ada ptm ygy https://t.co/lmyicodnts         belom ada ptm ygy    \n",
       "2                  twt sepi bgt pada ptm yaa  twt sepi bgt pada ptm yaa   \n",
       "3                  oi kalian ptm nya gimana?  oi kalian ptm nya gimana?   \n",
       "4                     sp yg hr ini ptm cungg     sp yg hr ini ptm cungg   \n",
       "\n",
       "                  remove_num                punctuation  \\\n",
       "0  gua harusnya hari ini ptm  gua harusnya hari ini ptm   \n",
       "1         belom ada ptm ygy          belom ada ptm ygy    \n",
       "2  twt sepi bgt pada ptm yaa  twt sepi bgt pada ptm yaa   \n",
       "3  oi kalian ptm nya gimana?   oi kalian ptm nya gimana   \n",
       "4     sp yg hr ini ptm cungg     sp yg hr ini ptm cungg   \n",
       "\n",
       "                     tokenized_text                   stopwords  \\\n",
       "0   [gua, harusnya, hari, ini, ptm]                  [gua, ptm]   \n",
       "1            [belom, ada, ptm, ygy]           [belom, ptm, ygy]   \n",
       "2  [twt, sepi, bgt, pada, ptm, yaa]  [twt, sepi, bgt, ptm, yaa]   \n",
       "3    [oi, kalian, ptm, nya, gimana]      [oi, ptm, nya, gimana]   \n",
       "4     [sp, yg, hr, ini, ptm, cungg]    [sp, yg, hr, ptm, cungg]   \n",
       "\n",
       "                      stemmed  \n",
       "0                  [gua, ptm]  \n",
       "1           [belom, ptm, ygi]  \n",
       "2  [twt, sepi, bgt, ptm, yaa]  \n",
       "3      [oi, ptm, nya, gimana]  \n",
       "4    [sp, yg, hr, ptm, cungg]  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      {'gua': 1, 'harusnya': 1, 'hari': 1, 'ini': 1,...\n",
       "1             {'belom': 1, 'ada': 1, 'ptm': 1, 'ygy': 1}\n",
       "2      {'twt': 1, 'sepi': 1, 'bgt': 1, 'pada': 1, 'pt...\n",
       "3      {'oi': 1, 'kalian': 1, 'ptm': 1, 'nya': 1, 'gi...\n",
       "4      {'sp': 1, 'yg': 1, 'hr': 1, 'ini': 1, 'ptm': 1...\n",
       "                             ...                        \n",
       "295    {'kita': 1, 'adalah': 1, 'remaja': 1, 'yang': ...\n",
       "296       {'ptm': 1, 'males': 1, 'bngt': 1, 'coookk': 1}\n",
       "297    {'kayaknya': 1, 'udah': 1, 'nyaman': 1, 'sekol...\n",
       "298    {'ptm': 2, 'shift': 1, 'digabung': 1, 'agaknya...\n",
       "299    {'gue': 1, 'ptm': 1, 'jadi': 1, 'pendiem': 1, ...\n",
       "Name: freq_token, Length: 300, dtype: object"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['freq_token']=data['tokenized_text'].apply(nltk.FreqDist).apply(lambda x: dict(x)) # Frequency word token\n",
    "\n",
    "data['freq_token']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (240,) (240,) Test:  ((60,), (60,))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data random 80%\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Train: \",X_train.shape,y_train.shape,\"Test: \",(X_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names:  ['0dmkgngj95' '10' '100' '12an' '17' '19' '1q2kmlkxol' '1vpywrykyo' '2022'\n",
      " '2jam']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create Tfidf vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "# vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Convert the 'review' column into its TF-IDF vectorized form\n",
    "X = vectorizer.fit_transform(df['tokenized_text'])\n",
    "\n",
    "# Get the feature names (word tokens)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(\"Feature Names: \",feature_names[:10]) # Print only first 5 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train and Evaluate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score    support\n",
      "0              0.280000  0.437500  0.341463  16.000000\n",
      "1              0.684211  0.590909  0.634146  22.000000\n",
      "2              0.562500  0.409091  0.473684  22.000000\n",
      "accuracy       0.483333  0.483333  0.483333   0.483333\n",
      "macro avg      0.508904  0.479167  0.483098  60.000000\n",
      "weighted avg   0.531794  0.483333  0.497261  60.000000\n",
      "\n",
      "Accuracy of the model: 48.33%\n"
     ]
    }
   ],
   "source": [
    "# Convert training and test datasets into vectorized form\n",
    "X_train_vectorized =  vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Create a Multinomial Naive Bayes model\n",
    "model = MultinomialNB(alpha=1)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Predict sentiment for test dataset\n",
    "y_pred = model.predict(X_test_vectorized)\n",
    "\n",
    "report=classification_report(y_test, y_pred,output_dict=True)\n",
    "print(pd.DataFrame(report).transpose())\n",
    "\n",
    "# Calculate accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred, normalize=True)\n",
    "print(f'\\nAccuracy of the model: {accuracy*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
